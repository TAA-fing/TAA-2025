{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qjsf78ymkS0E"
      },
      "source": [
        "#  <center> Taller  de Aprendizaje Automático </center>\n",
        "##  <center> Taller 9: *Natural Language Processing* (NLP)  </center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUfgw7Siq3td"
      },
      "source": [
        "## Introducción"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4y3HbLOkOVD"
      },
      "source": [
        "La siguiente actividad propone el abordaje de un problema de procesamiento de lenguaje natural (NLP) utilizando herramientas de *embedding* y modelos RNN. El conjunto de datos que se utilizará es IMDb, el cual corresponde a un problema de clasificación donde se tienen 50000 criticas de películas (35000 de *train* y 15000 de *test*), y se quiere estimar si éstas son críticas positivas (1) o negativas (0).\n",
        "\n",
        "La propuesta consiste en entender y reproducir los pasos de la sección *Sentiment Analysis* para los datos **sin procesar**, agregando algunas variantes como mitigar el sobreajuste y entender la herramienta *embeddings*.\n",
        "\n",
        "En este Taller también se introduce la biblioteca *Streamlit*, utilizada para desarrollar prototipos de aplicaciones web de aprendizaje automático. Aquellos que así lo deseen, podrán generar de manera sencilla una aplicación web que clasifique las críticas proporcionadas por los usuarios. Además, se presenta la biblioteca HuggingFace, la cual permite realizar inferencias con modelos preentrenados y realizar fine-tuning para adaptarlos a esta tarea específica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rY6vz2Ekj8ig"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "\n",
        "*   Aplicar modelos basados en RNN a un problema de NLP.\n",
        "*   Trabajar con embeddings para secuencias de texto, en particular embeddings preentrenados.\n",
        "*   Utilizar herramientas para la visualización de embeddings.\n",
        "*  (Opcional, no evaluado) Desarrollar una aplicación web que clasifique críticas proporcionadas por los usarios\n",
        "*  (Opcional, no evaluado) Utilizar la biblioteca *HuggingFace* para utilizar modelos preentrenados y realizar fine-tunning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "common-destiny"
      },
      "source": [
        "## Formas de trabajo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVgxoLgl1-KA"
      },
      "source": [
        "### Opción 1: Trabajar localmente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moral-gallery"
      },
      "source": [
        "Descargar los datos en su máquina personal y trabajar en su propio ambiente de desarrollo.\n",
        "\n",
        "`conda activate TAA-py310`              \n",
        "`jupyter-notebook`    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfcTy55R2A7w"
      },
      "source": [
        "Los paquetes faltantes se pueden instalar desde el notebook haciendo:     \n",
        "` !pip install paquete_faltante`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lined-sport"
      },
      "source": [
        "### Opción 2:  Trabajar en *Colab*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lined-candle"
      },
      "source": [
        "<table align=\"center\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/TAA-fing/TAA-2025/blob/main/talleres/taller9_NLP.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Ejecutar en Google Colab</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "expensive-jewel"
      },
      "source": [
        "Se puede trabajar en Google Colab. Para ello es necesario contar con una cuenta de **google drive** y ejecutar un notebook almacenado en dicha cuenta. De lo contrario, no se conservarán los cambios realizados en la sesión. En caso de ya contar con una cuenta, se puede abrir el notebook y luego ir a `Archivo-->Guardar una copia en drive`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8OOpzq91ITq"
      },
      "source": [
        "La siguiente celda realiza la configuración necesaria para obtener datos desde la plataforma Kaggle. Le solicitará que suba el archivo *kaggle.json* asociado a su cuenta."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:15.018423Z",
          "start_time": "2022-06-08T19:24:15.011294Z"
        },
        "id": "LlKwJ6sKmhBt"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from google.colab import files\n",
        "\n",
        "# El siguiente archivo solicitado es para habilitar la API de Kaggle en el entorno que está trabajando.\n",
        "# Este archivo se descarga entrando a su perfíl de Kaggle, en la sección API, presionando donde dice: Create New API Token\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "    print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))\n",
        "\n",
        "#Then move kaggle.json into the folder where the API expects to find it.\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xj1R6mm14u0t"
      },
      "source": [
        "# Parte 1: Análisis y preprocesamiento de datos\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M44JXP4Z41BI"
      },
      "source": [
        "Se utilizará el conjunto de IMDb provisto por Kaggle. Se tienen 50000 criticas de películas que al igual que en el *Taller 2* se utilizarán 35000 para *train* y 15000 para *test*.\n",
        "\n",
        "*   Ejecutar la siguiente celda para descargar el conjunto y verificar que los conjuntos tienen la cantidad de instancias esperadas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.584675Z",
          "start_time": "2022-06-08T19:24:23.473981Z"
        },
        "id": "CwAZeeqamXo2"
      },
      "outputs": [],
      "source": [
        "# Descarga la base IMDb de Kaggle\n",
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.601403Z",
          "start_time": "2022-06-08T19:24:23.590754Z"
        },
        "id": "nj1ZMjmtn3cX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "# Se descomprime el archivo descargado\n",
        "with zipfile.ZipFile('imdb-dataset-of-50k-movie-reviews.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('')\n",
        "\n",
        "# Se levanta como pandas DataFrame\n",
        "data_file = 'IMDB Dataset.csv'\n",
        "data = pd.read_csv(data_file)\n",
        "\n",
        "#Separación de Conjuntos\n",
        "N=35000\n",
        "X_train = data.loc[:N-1, 'review'].values\n",
        "y_train = data.loc[:N-1, 'sentiment'].values == 'positive'\n",
        "X_test = data.loc[N:, 'review'].values\n",
        "y_test = data.loc[N:, 'sentiment'].values == 'positive'\n",
        "\n",
        "# Armado de los Tensorflow Datasets\n",
        "data_train = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "data_test = tf.data.Dataset.from_tensor_slices((X_test, y_test))\n",
        "\n",
        "#Verificación\n",
        "print('Train Size:', len(data_train),'Test Size:', len(data_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQpeE5zh8ZlC"
      },
      "source": [
        "*   Del conjunto de entrenamiento visualizar tanto una review positiva como una negativa. Se sugiere ir a los Notebooks del *Capítulo 16*. Puede ser útil el uso del método *.skip()*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.608069Z",
          "start_time": "2022-06-08T19:24:20.153Z"
        },
        "id": "SMp1E9d27ro5"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYU0vZiD65J1"
      },
      "source": [
        "*   Reservar unas 5000 críticas de los datos de entrenamiento para validación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.608859Z",
          "start_time": "2022-06-08T19:24:20.156Z"
        },
        "id": "D55BIKVp7M2K"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTQ3PHH338ys"
      },
      "source": [
        "* Prepare los batches para todos los conjuntos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIFFRf6e4BmI"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEdt3JsjIjIS"
      },
      "source": [
        "*   Keras proporciona una capa de `TextVectorization` para el preprocesamiento básico de texto. Explique el funcionamiento y adapte una capa para los datos de entrenemiento en cuestión. Se sugiere leer la sección asociada a esta capa en el *Capítulo 13* del libro. Utilice un tamaño de vocabulario de 10000 palabras.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhvC46EhHf2K"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMkt4V3_4NGm"
      },
      "source": [
        "* Obtenga el diccionario de la capa `TextVectorization`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-LMMrdwH4YP"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TL0ayaj4C90z"
      },
      "source": [
        "* Siguiendo el ejemplo adjunto en la [documentación](https://www.tensorflow.org/api_docs/python/tf/keras/layers/TextVectorization) de la capa `TextVectorization`. Cree un modelo de keras que cuente únicamente con esta capa y observe el resultado de pasar una crítica cualquiera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSzYSkpPC9sr"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUSqc8-o4Xj2"
      },
      "source": [
        "*   Utilizando esta capa ¿cuáles son los largos de secuencias para los primeros *batches*? ¿Es un problema a resolver que todos tengan largos distintos? ¿Por qué?."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RP2mCScC4Zz4"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNZlLb6v4OHS"
      },
      "source": [
        "# Parte 2: *Embedding*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZeKwMu4dlD"
      },
      "source": [
        "* Cree y entrene el modelo que aparece al final de la sección *Sentiment Analysis* y previo a la sección *Masking* del *Capítulo 16*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1zMpB7iC9sr"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYunxz_uRruE"
      },
      "source": [
        "* Implemente el uso de *Masking* en el modelo que ya utilizó. ¿Por qué podría ser esto útil para el aprendizaje?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24pjFwc0C9sr"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz0ynw4zy1w5"
      },
      "source": [
        "* Observe que el modelo se sobreajusta a los datos. Utilice alguna técnica vista para regularizar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "InJVu0DpC9ss"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqU7n4gMZc5X"
      },
      "source": [
        "* El modelo cuenta con una capa de entrada de *embedding* la cual abarca la mayoría de los parámetros entrenables. En este caso un *embedding* es un vector entrenable que representa una palabra en nuevo espacio cuyo tamaño es un hiperparámetro. La concatenación de estos vectores conforma la matriz de *embedding*, donde su cantidad de filas corresponde a la suma del tamaño del vocabulario y la cantidad de columnas a las dimensiones de los vectores (*embed_size*). Al igual que una matriz de pesos, ésta se inicializa de forma aleatoria, y actualiza sus valores para cada *step* de entrenamiento.\n",
        "\n",
        "  *   ¿Cuál es la ventaja de utilizar una capa de *embedding*? (Ver la sección *Encoding Categorical Features Using Embeddings* del *Capítulo 13* del libro.)\n",
        "  *   Visualizar una representación del espacio de *embedding* utilizando *Comet*. **Importante:** para evitar errores, modifique del diccionario el valor del espacio por `<pad>`.\n",
        "\n",
        "  Para este último punto se recomienda seguir el siguiente ejemplo: [logging-embeddings](https://www.comet.ml/docs/user-interface/embeddings/#logging-embeddings).\n",
        "\n",
        "*   Para su mejor modelo: visualizar a qué distancias se encuentran las palabras unas de otras tanto en la representación a baja dimensión como en el espacio de *embedding*. Sobre todo probar con adjetivos positivos (*wonderful*, *excellent*, etc.) y negativos (*ugly*, *boring*, etc.) comparando los resultados. ¿Qué logra observar?."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfSujuskbZog"
      },
      "source": [
        "# Parte 3: *Embedding Preentrenado*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4y9GduFbiZD"
      },
      "source": [
        "Una de las técnicas para mejorar el desempeño en este tipo de problemas es utilizar *embeddings* ya entrenados.\n",
        "Siguiendo el ejemplo [Using pre-trained word embeddings](https://keras.io/examples/nlp/pretrained_word_embeddings/):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACU7xlN8bqzP"
      },
      "source": [
        "*   Descargar el *embedding* preentrenado [GloVE](https://nlp.stanford.edu/projects/glove/) que aparece en la sección *Load pre-trained word embeddings*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.618500Z",
          "start_time": "2022-06-08T19:24:20.229Z"
        },
        "id": "R368yCtObhyk"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9ARmJXcbyhU"
      },
      "source": [
        "* Preparar la nueva matriz de *embedding*. ¿Cuántas palabras del conjunto de entrenamiento se encuentran en el vocabulario de GloVE? ¿Cuántas no?."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.619152Z",
          "start_time": "2022-06-08T19:24:20.231Z"
        },
        "id": "7nfz9Ee1b0yP"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipkjXoNecR2_"
      },
      "source": [
        "* Entrenar el modelo con la nueva matriz de *embedding* de manera que los valores de ésta se mantengan fijos (ver parámetro en la capa de *embedding*). Utilice masking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7smspfWGC9sw"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwqxdPALEyJ4"
      },
      "source": [
        "* Entrene nuevamente el modelo pero con el *embedding* entrenable. Modifique el *learning rate*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLKSMCJnC9sw"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0_RrsTZsaKM"
      },
      "source": [
        "*   Comparar con los modelos anteriores en cuanto al desempeño, la cantidad de parámetros y el tiempo de entrenamiento.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLwg3ZMKC9sx"
      },
      "source": [
        "Respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Af_D4NTCsezj"
      },
      "source": [
        "*   Visualizar cómo es el espacio de *embedding*. ¿Qué diferencias puede observar con respecto al anterior?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4tsZq6m2FMjv"
      },
      "source": [
        "Respuesta:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QnyfpJny_Eq-"
      },
      "source": [
        "# Parte 4: Mejoras en los Modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcsXZdnYo-sl"
      },
      "source": [
        "Se sugieren algunas líneas que podrían mejorar los desempeños obtenidos en las partes anteriores:\n",
        "\n",
        "* Ampliar el tamaño del vocabulario utilizado durante el entrenamiento, junto con aumentar la complejidad del modelo.\n",
        "* Implementar una función de preprocesamiento de texto que realice tareas como eliminar las etiquetas HTML, eliminar números y llevar a cabo otras acciones relevantes.\n",
        "* Considerar la utilización de n-gramas y/o modificar el tokenizador utilizado.\n",
        "* Evaluar el cambio de las neuronas recurrentes de GRU a LSTM.\n",
        "\n",
        "Piense por qué tiene sentido explorar estas estrategias y pruebe alguna que considere relevante o proponga alguna otra que le parezca relevante.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iw28DePgC9sx"
      },
      "outputs": [],
      "source": [
        "# ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90O_LXGExzWp"
      },
      "source": [
        "# Parte 5: Desarrollo de una aplicación web (Opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAIXZ-_DNeN7"
      },
      "source": [
        "En esta parte veremos cómo generar una aplicación web sencilla que permita mostrar el funcionamiento de un modelo que hayamos entrenado. Para ello utilizaremos la biblioteca [Streamlit](https://streamlit.io/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-07T13:41:26.128144Z",
          "start_time": "2022-06-07T13:41:26.119600Z"
        },
        "id": "Oz7kKyFaF6uQ"
      },
      "source": [
        "## Streamlit\n",
        "Streamlit es una biblioteca de código abierto escrita en Python que permite crear y compartir aplicaciones web que usan algoritmos de aprendizaje automático. En la [documentación](https://docs.streamlit.io/) encontrará información sobre cómo instalar y crear aplicaciones utilizando la biblioteca. El flujo de trabajo básico consta de los siguientes pasos:   \n",
        "\n",
        "1. Instalación   \n",
        "2. Desarrollo de la aplicación   \n",
        "3. Desplieque de la aplicación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-07T13:42:20.285367Z",
          "start_time": "2022-06-07T13:42:20.280067Z"
        },
        "heading_collapsed": true,
        "id": "G_y-rIEzF6uQ"
      },
      "source": [
        "### Instalación\n",
        "En la mayoría de los casos, la biblioteca debería quedar instalada luego de crear un ambiente virtual (por ejemplo de conda) y hacer:   \n",
        "\n",
        "`pip install streamlit`  \n",
        "\n",
        "Puede verificar que la instalación sea correcta haciendo:    \n",
        "\n",
        "`streamlit hello`\n",
        "\n",
        "Puede ver los detalles de instalación en https://docs.streamlit.io/library/get-started/installation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-07T13:43:13.534243Z",
          "start_time": "2022-06-07T13:43:13.529929Z"
        },
        "id": "ACy7SerfF6uR"
      },
      "source": [
        "### Desarrollo de la aplicación  \n",
        "\n",
        "Se sugiere desarrollar la aplicación partiendo de un ejemplo que clasifica críticas de cine utilizando un modelo entrenado con las técnicas vistas en el Taller 2. Dicho ejemplo puede verse en funcionamiento [acá](https://share.streamlit.io/taa-fing/taa-2022/main/apps/movie_review_app/movie_review_app.py). La siguiente celda descarga el código fuente y lo descomprime."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.630093Z",
          "start_time": "2022-06-08T19:24:20.258Z"
        },
        "id": "6s5kTwpCF6uR"
      },
      "outputs": [],
      "source": [
        "!wget iie.fing.edu.uy/~carbajal/movie_review/apps.zip\n",
        "!unzip apps.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDw4xQQ_F6uR"
      },
      "source": [
        "Copie el archivo *movie_review_app.py*, modifique el nombre, y realice las siguientes modificaciones (además de las de diseño que crea conveniente):   \n",
        "\n",
        "**Cambio de Modelo:**  Para hacer inferencia fuera de este *Notebook* será necesario contar con el modelo entrenado. El modelo se puede guardar con alguna de las técnicas vistas en el curso. Se sugiere utilizar el *Callback* **ModelCheckpoint**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYAdJltN6iWw"
      },
      "source": [
        "**Modificación del pipeline de inferencia:**  El objetivo es generar una función que a partir de una única reseña prediga si la reseña es *positiva*(1) o *negativa*(0). Para ello se brinda una función a completar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.632348Z",
          "start_time": "2022-06-08T19:24:20.263Z"
        },
        "id": "wWkkHf_67KPS"
      },
      "outputs": [],
      "source": [
        "# Pipeline funtion to make inference\n",
        "def pipeline_inference (review, model):\n",
        "\n",
        "  '''\n",
        "  Función que prepara una review aislada y hace inferencia con el modelo.\n",
        "\n",
        "  Entradas:\n",
        "    review: String con la review a hacer inferencia\n",
        "    model: Modelo entrenado con el que se realiza inferencia\n",
        "\n",
        "  Salida:\n",
        "\n",
        "    pred: Predicción del modelo\n",
        "\n",
        "  '''\n",
        "\n",
        "  # ...\n",
        "\n",
        "  return pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_2uml4vSIvi"
      },
      "source": [
        "* Las siguientes celdas prueban la función. Verifique que funciona correctamente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.633515Z",
          "start_time": "2022-06-08T19:24:20.265Z"
        },
        "id": "qN9RStj0DQD_"
      },
      "outputs": [],
      "source": [
        "# Load model\n",
        "checkpoint_filepath = '/content/...'\n",
        "\n",
        "model_loaded = keras.models.load_model(checkpoint_filepath)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.634730Z",
          "start_time": "2022-06-08T19:24:20.266Z"
        },
        "id": "ePLSyMO1BMuX"
      },
      "outputs": [],
      "source": [
        "review = 'This movie is really boring. I do not recommend it.'\n",
        "\n",
        "pred = pipeline_inference(review, model_loaded)\n",
        "\n",
        "pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2022-06-08T19:24:23.636273Z",
          "start_time": "2022-06-08T19:24:20.268Z"
        },
        "id": "WmV5G1WRTDpi"
      },
      "outputs": [],
      "source": [
        "review = 'This movie is wonderful. I love it.'\n",
        "\n",
        "pred = pipeline_inference(review, model_loaded)\n",
        "\n",
        "pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bE1B8l8vF6uT"
      },
      "source": [
        "### Correr la aplicación localmente"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbsE4S8VF6uT"
      },
      "source": [
        "Una vez realizadas las modificaciones en el archivo principal, cree un directorio donde guardar los archivos de su aplicación. Guarde allí el modelo, el archivo tipo numpy con las palabras y su archivo principal (Ej. *movie_review_app.py*)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Xm1pGUmbV6_"
      },
      "source": [
        "* Una vez modificado el código, puede probarlo localmente. Para ello ejecute el siguiente comando, sustituyendo *movie_review_app.py* por el nombre de su archivo principal.\n",
        "\n",
        "\n",
        "`!streamlit run apps/movie_review_app/movie_review_app.py`    \n",
        "\n",
        "* Si en vez de localmente, está corriendo el notebook en Colab, ejecute:\n",
        "\n",
        "`!streamlit run apps/movie_review_app/movie_review_app.py & npx localtunnel --port 80`      "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIsigqf7F6uU"
      },
      "source": [
        "### Despliegue de la aplicación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKXAqZA4uAYA"
      },
      "source": [
        "Una vez que la app fue desarrollada es posible compartirla para que otros puedan probarla. Para ello es necesario:  \n",
        "\n",
        "1. Contar con una cuenta de [Streamlit Cloud](https://docs.streamlit.io/streamlit-cloud/get-started#sign-up-for-streamlit-cloud) y un repositorio de GitHub donde almacenar el código.\n",
        "2.  Subir al repositorio  el código y los datos necesarios para correrlo.\n",
        "3. [Conectar la cuenta de Streamlit Cloud con la del repositorio](https://docs.streamlit.io/streamlit-cloud/get-started#connect-your-github-account).     \n",
        "4. [Publicar la app](https://docs.streamlit.io/streamlit-cloud/get-started/deploy-an-app)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rN0y6d6rvO_u"
      },
      "source": [
        "*Comentario:* Puede que sea necesario agregar en el repositorio un archivo *requirements.txt* donde deba especificar las liberías utilizas en el archivo *main.py*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wu0Q1R8L8sv5"
      },
      "source": [
        "# Parte 6: Uso de la liberería HuggingFace (Opcional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kmzCN_m_Fj-"
      },
      "source": [
        "Hugging Face es una organización de desarrolladores que utilizan una [plataforma](https://huggingface.co/) para compartir y desarrollar modelos de código abierto con arquitectura de Transformers, centrados principalmente en procesamiento de lenguaje natural, aunque también cuentan con modelos para procesamiento de imágenes y señales de audio.  \n",
        "\n",
        "Los modelos son desarrollados con técnicas del estado del arte, y entrenados con grandes volumnes de datos y capacidad de computo. Cualquier persona que quiera hacer uso de los modelos pre-entrenados puede hacerlo simplemente instalando la biblioteca de Transformers y los módulos necesarios para las tareas a implementar.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ka4Wb85h_Yh7"
      },
      "source": [
        "## Uso de modelo preentrenado para hacer inferencia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzwVV4xzdUCP"
      },
      "source": [
        "Este código utiliza la biblioteca de HuggingFace \"transformers\" para importar y utilizar un modelo preentrenado de análisis de sentimientos. En este caso, se utiliza el modelo \"sentiment-analysis\", que se encarga de clasificar el sentimiento de un texto dado como positivo o negativo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pTV-xjTz-Hp4"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    %pip install -q -U transformers\n",
        "    %pip install -q -U datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XNHpyRbEdzBe"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "result = classifier(\"The movie was horrible.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "790-Oe-ud1kQ"
      },
      "outputs": [],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOanaaqueU_M"
      },
      "source": [
        "Utilizando este modelo realice inferencia sobre el conjunto de test, y evalue el desempeño obtenido. Compárelo con los obtenidos anteriormente."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKGWhmHYeOY5"
      },
      "outputs": [],
      "source": [
        "N_test = X_test.shape[0]\n",
        "\n",
        "pred_test = np.zeros(N_test)\n",
        "\n",
        "for i in range(N_test):\n",
        "  result = classifier(X_test[i][:1500]) # Corta la review a 1500 caracteres para adaptarse al modelo\n",
        "  if result[0]['label'] == 'NEGATIVE':\n",
        "    pred_test[i] = 1 - result[0]['score']\n",
        "  else:\n",
        "    pred_test[i] = result[0]['score']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIOuSZhweSRI"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(y_test, pred_test > 0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_N0puYDqewvQ"
      },
      "source": [
        "## Fine-tuning de un modelo ya pre-entrenado\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgvNcM5c5OvE"
      },
      "source": [
        "Para ejecutar esta parte del notebook, deberá reiniciar el entorno de ejecución.\n",
        "\n",
        "La siguiente celda instala las bibliotecas necesarias para esta parte."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-8opdWUlX6J"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# Instalamos la biblioteca con los modelos de arquitectura Transformer\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG38vGCE5RDr"
      },
      "source": [
        "El objetivo será realizar un ajuste de parámetros al modelo utilizando los datos del problema de interés, por lo tanto la siguiente celda levanta nuevamente los datos de la críticas de cine IMBd."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qj_Q1RwtZdQ"
      },
      "outputs": [],
      "source": [
        "# Se levanta como pandas DataFrame (Se requiere tener el csv descargado de la página de Kaggle)\n",
        "data_file = 'IMDB Dataset.csv'\n",
        "data = pd.read_csv(data_file)\n",
        "\n",
        "# Reduce el largo de las reviews a 1500 caracteres\n",
        "data['review'] = data['review'].str[:1500]\n",
        "\n",
        "# Convierte las etiquetas de sentimiento a 1 y 0\n",
        "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
        "\n",
        "# Print los datos actualizados\n",
        "print(data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZ6YAawCuWEk"
      },
      "outputs": [],
      "source": [
        "data.iloc[0]['review']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6ep8sEu5SGD"
      },
      "source": [
        "**Armado de Conjuntos** Se arman los datasets de Torch para realizar el entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKy2juiLjJy4"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "\n",
        "# Convertir los pandas DataFrames a datasets\n",
        "train_data = datasets.Dataset.from_pandas(data[:20000]) # Se cortan la cantidad de reseñas para reducir el costo computacional de la ejecucción.\n",
        "val_data = datasets.Dataset.from_pandas(data[30000:35000])\n",
        "test_data = datasets.Dataset.from_pandas(data[35000-1:])\n",
        "\n",
        "# Renombrar las columnas para que coincidan con los nombres esperados por el modelo\n",
        "train_data = train_data.rename_column(\"sentiment\", \"label\")\n",
        "val_data = val_data.rename_column(\"sentiment\", \"label\")\n",
        "test_data = test_data.rename_column(\"sentiment\", \"label\")\n",
        "train_data = train_data.rename_column(\"review\", \"text\")\n",
        "val_data = val_data.rename_column(\"review\", \"text\")\n",
        "test_data = test_data.rename_column(\"review\", \"text\")\n",
        "\n",
        "# Crear un DatasetDict\n",
        "emotions = datasets.DatasetDict({\n",
        "    \"train\": train_data,\n",
        "    \"validation\": val_data,\n",
        "    \"test\": test_data\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dKL_eCUiG6f"
      },
      "outputs": [],
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFIaFB7sif7H"
      },
      "outputs": [],
      "source": [
        "train_ds[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlDD4_jp5TnK"
      },
      "source": [
        "**Preparación de los datos** Los datos se pasan por el mismo tokenizer que se uso para el modelo de base que se utilizará. HuggingFace tiene un método \"AutoTokenizer\" para esto (simplemente determina cual es el tokenizer para ese modelo y lo aplica)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fOQqhbVZfWtY"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_ckpt='distilbert-base-uncased'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KylIPaQB5eGM"
      },
      "source": [
        "Finalmente implementamos una función para aplicar el tokenizer a todo el conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aHDvzHjnfnlQ"
      },
      "outputs": [],
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch['text'], padding=True,truncation=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aLuPJDbKfuCF"
      },
      "outputs": [],
      "source": [
        "emotions_encoded = emotions.map(tokenize,batched=True,batch_size=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDKjAbs_5mVm"
      },
      "source": [
        " **Fine-tuning de un modelo**\n",
        "\n",
        " En primer lugar se levanta el modelo a ajustar y luego se procede a entrenarlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VJz5QMlf0fX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "num_labels = 6\n",
        "\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt,num_labels = num_labels).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Impwq8SGkmzX"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels,preds,average=\"weighted\")\n",
        "  acc = accuracy_score(labels,preds)\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SU5r9XPZkpBN"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 32\n",
        "logging_steps = len(emotions_encoded[\"train\"])\n",
        "model_name = f\"{model_ckpt}-finetuned-emotions\"\n",
        "training_args = TrainingArguments(output_dir = model_name,\n",
        "                                  num_train_epochs = 2,\n",
        "                                  learning_rate= 2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  push_to_hub=False,\n",
        "                                  log_level=\"error\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38qeDwU7kqzJ"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  compute_metrics = compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset = emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFoa3TEMlsQo"
      },
      "outputs": [],
      "source": [
        "preds_output = trainer.predict(emotions_encoded[\"test\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRC_QLvilug3"
      },
      "outputs": [],
      "source": [
        "preds_output.metrics"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "SUfgw7Siq3td",
        "rY6vz2Ekj8ig",
        "xVgxoLgl1-KA",
        "Xj1R6mm14u0t",
        "VNZlLb6v4OHS",
        "PfSujuskbZog",
        "QnyfpJny_Eq-",
        "90O_LXGExzWp"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}